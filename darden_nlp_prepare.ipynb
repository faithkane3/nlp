{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nlp_acquire import get_news_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>What is Natural Language Processing?</font>\n",
    "\n",
    "Natural Language Processing allows you to use techniques in Python libraries like NLTK (Natural Language Tool Kit) and Spacy to create a machine-useable structure out of natural language text. In other words, you can manipulate natural language in such a way that renders it useful in machine learning. Machines can't read words, but they can recognize numbers, so we have to process the text we want to use in a way that retains the original meaning while representing the text with numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>So What?</font>\n",
    "\n",
    "We will establish a workflow to preprocess our text data and prepare it for further use in exploration and modeling. This preprocessing is know as text normalization. **Normalization** is when you perform a series of tasks like making all text lowercase, removing punctuation, expanding contractions, removing anything that's not an ASCII character, etc.\n",
    "\n",
    "1. Lowercase all characters in our string.\n",
    "2. Remove special characters from our string.\n",
    "3. Remove accented characters from our string.\n",
    "4. Tokenize our string into discrete units. (words, punctuation)\n",
    "5. Stem and Lemmatize the words in our string. (group by base word)\n",
    "6. Remove stopwords from our string. (remove noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>Now What?</font>\n",
    "\n",
    "Let's create functions to help us normalize our text data. According to the curriculum, we should build our functions to take in a string. We can use the `.apply()` method when it's time to use our functions on a Series in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vacc...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Father said 'if you want to blow money up, fin...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>China suspends fish imports from Indian firm a...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>China has suspended imports from India's Basu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Russian vaccine arrives in India, video of it ...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>Russia's coronavirus vaccine, Sputnik V, has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Special Indian version of PUBG Mobile to be la...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>South Korea's PUBG Corporation on Thursday ann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  Scientist behind '90% effective' COVID-19 vacc...   \n",
       "1  business  Father said 'if you want to blow money up, fin...   \n",
       "2  business  China suspends fish imports from Indian firm a...   \n",
       "3  business  Russian vaccine arrives in India, video of it ...   \n",
       "4  business  Special Indian version of PUBG Mobile to be la...   \n",
       "\n",
       "                   author                                            content  \n",
       "0  Krishna Veera Vanamali  German scientist Uğur Şahin, the CEO of BioNTe...  \n",
       "1          Pragya Swastik  Serum Institute of India's (SII) CEO Adar Poon...  \n",
       "2  Krishna Veera Vanamali  China has suspended imports from India's Basu ...  \n",
       "3  Krishna Veera Vanamali  Russia's coronavirus vaccine, Sputnik V, has a...  \n",
       "4  Krishna Veera Vanamali  South Korea's PUBG Corporation on Thursday ann...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read our text data into a pandas DataFrame from our saved json file.\n",
    "\n",
    "df = get_news_articles(cached=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    German scientist Uğur Şahin, the CEO of BioNTe...\n",
       "1    Serum Institute of India's (SII) CEO Adar Poon...\n",
       "2    China has suspended imports from India's Basu ...\n",
       "3    Russia's coronavirus vaccine, Sputnik V, has a...\n",
       "4    South Korea's PUBG Corporation on Thursday ann...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = df.content\n",
    "print(type(articles))\n",
    "articles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protection only from symptomatic infections will have a dramatic effect,\" Şahin said.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a string that I will use to test my funtions; this is just the first row in my Series.\n",
    "\n",
    "article = articles[0]\n",
    "print(type(article))\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lowercase Text\n",
    "```python\n",
    "# Make all characters in string lowercase.\n",
    "string = string.lower()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uğur şahin, the ceo of biontech which co-developed a coronavirus vaccine with pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" the vaccine is 90% effective based on initial data from a late-stage trial. \"i believe that even protection only from symptomatic infections will have a dramatic effect,\" şahin said.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note I have to reassign this to save the changes.\n",
    "\n",
    "article = article.lower()\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Special Characters\n",
    "\n",
    "Here are two common patterns I might want to use to remove special characters; it just depends on what you want to remain in your string.\n",
    "\n",
    "```python\n",
    "# Remove characters that are not letters, underscores, or spaces.\n",
    "string = re.sub(r'[^\\w\\s]', '', string)\n",
    "\n",
    "# Remove characters that are not letters, numbers, single quotes, or spaces.\n",
    "string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uğur şahin the ceo of biontech which codeveloped a coronavirus vaccine with pfizer said hes confident his product can end the pandemic and bash the virus over the head the vaccine is 90 effective based on initial data from a latestage trial i believe that even protection only from symptomatic infections will have a dramatic effect şahin said'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test our regex on our string first; we have to reassign if we want to save the changes.\n",
    "\n",
    "article = re.sub(r'[^\\w\\s]', '', article)\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Accented Characters\n",
    "\n",
    "We will remove accented characters by chaining together the following methods:\n",
    "\n",
    "```python\n",
    "# Remove inconsistencies in unicode character encoding.\n",
    "string = unicodedata.normalize(form, unistr)\n",
    "```\n",
    "\n",
    "```python\n",
    "# Convert string to ASCII character set and drop non-ASCII characters.\n",
    "string = string.encode('ascii', 'ignore')\n",
    "```\n",
    "\n",
    "```python\n",
    "# Convert the bytes back into a string object.\n",
    "string = string.decode('utf-8', 'ignore')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin the ceo of biontech which codeveloped a coronavirus vaccine with pfizer said hes confident his product can end the pandemic and bash the virus over the head the vaccine is 90 effective based on initial data from a latestage trial i believe that even protection only from symptomatic infections will have a dramatic effect ahin said'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to reassign to my variable if I want to save the changes.\n",
    "\n",
    "article = unicodedata.normalize('NFKC', article).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Clean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKC', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin the ceo of biontech which codeveloped a coronavirus vaccine with pfizer said hes confident his product can end the pandemic and bash the virus over the head the vaccine is 90 effective based on initial data from a latestage trial i believe that even protection only from symptomatic infections will have a dramatic effect ahin said'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = basic_clean(article)\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Text\n",
    "\n",
    "**Tokenization** - is when you split larger strings of text into smaller pieces or tokens by setting a boundary. You might chunk a sentence into words using a space as a boundary or a paragraph into sentences using punctuation as a boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK Tokenization\n",
    "\n",
    "```python\n",
    "# Create the tokenizer\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "# Use the tokenizer on my string and assign to a variable. \n",
    "tokenized_string = tokenizer.tokenize(string, return_str=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenizer\n",
    "\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin the ceo of biontech which codeveloped a coronavirus vaccine with pfizer said hes confident his product can end the pandemic and bash the virus over the head the vaccine is 90 effective based on initial data from a latestage trial i believe that even protection only from symptomatic infections will have a dramatic effect ahin said'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the tokenizer to my string.\n",
    "\n",
    "tokenized_article = tokenizer.tokenize(article, return_str=True)\n",
    "tokenized_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stem Words\n",
    "\n",
    "**Stemming** is when you reduce related words in your text to their common stem. It can make it easier when you are searching for a particular word in your text to search for their common stem rather than every form of the word. Stemmers aren't that sophisticated in the way they chop off word endings at their common stems; Spacy, another python NLP library, doesn't even include a stemmer in their library. Spacy only offers the more sophisticated lemmatizer, which we will look at in NLTK next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK PorterStemmer\n",
    "\n",
    "```python\n",
    "# Create the Stemmer.\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Apply the stemmer to each word in our string.\n",
    "stems = [ps.stem(word) for word in string.split()]\n",
    "```\n",
    "\n",
    "```python\n",
    "# Join our lists of words into strings again and assign to a variable.\n",
    "stemmed_string = ' '.join('stems')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create porter stemmer\n",
    "\n",
    "ps = nltk.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['german',\n",
       " 'scientist',\n",
       " 'uur',\n",
       " 'ahin',\n",
       " 'the',\n",
       " 'ceo',\n",
       " 'of',\n",
       " 'biontech',\n",
       " 'which',\n",
       " 'codevelop']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the stemmer to each word in our string.\n",
    "\n",
    "stems = [ps.stem(word) for word in article.split()]\n",
    "stems[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin the ceo of biontech which codevelop a coronaviru vaccin with pfizer said he confid hi product can end the pandem and bash the viru over the head the vaccin is 90 effect base on initi data from a latestag trial i believ that even protect onli from symptomat infect will have a dramat effect ahin said'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join our lists of words into a string again and assign to a variable. Take a peek.\n",
    "\n",
    "stemmed_string = ' '.join(stems)\n",
    "stemmed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stem Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize Tokens\n",
    "\n",
    "**Lemmatization** - is when you reduce related words in your text to their lemma or word base by applying a morphological analysis to your text. Like stemming, this is done to reduce the number of forms you have of the same word, so they can be analyzed as a single item. While stemming might create tokens that are not actually words anymore after they have been chopped off at their base, lemmatization will leave you with real words. A drawback to lemmatization is that it takes longer than stemming; you can try both to see which gives you better results as you analyze a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK WordNetLemmatizer\n",
    "\n",
    "```python\n",
    "# Download\n",
    "nltk.download('wordnet')\n",
    "```\n",
    "\n",
    "```python\n",
    "# Create the Lemmatizer.\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Use the lemmatizer on each word in the list of words we created by using split.\n",
    "lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "```\n",
    "\n",
    "```python\n",
    "# Join our list of words into a string again and assign to a variable.\n",
    "lemmatized_string = ' '.join(lemmas)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Lemmatizer.\n",
    "\n",
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the lemmatizer on each word in the list of words we created by using split.\n",
    "\n",
    "lemmas = [wnl.lemmatize(word) for word in article.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin the ceo of biontech which codeveloped a coronavirus vaccine with pfizer said he confident his product can end the pandemic and bash the virus over the head the vaccine is 90 effective based on initial data from a latestage trial i believe that even protection only from symptomatic infection will have a dramatic effect ahin said'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join our list of words into a string again and assign to a variable.\n",
    "\n",
    "lemmatized_string = ' '.join(lemmas)\n",
    "lemmatized_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there differences between the stemmed and lemmatized strings? Yes.\n",
    "\n",
    "stemmed_string == lemmatized_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords\n",
    "\n",
    "**Stopwords** - are words which are filtered out during the preparation of your text for analyzation and modeling. Stopwords are those that offer little to the meaning of your text and are basically just adding noise to your analysis. Or, as Ryan Orsinger would say, \"Stopwords aren't the real story of the document.\" Words such as 'the', 'and', 'a', and the like can be removed, so you can better focus on the good stuff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK Stopwords\n",
    "\n",
    "```python\n",
    "# Necessary import\n",
    "import nltk; nltk.download('stopwords')\n",
    "\n",
    "# Create list of stopwords and assign to variable.\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "# Create list of words and assign to variable.\n",
    "words = string.split()\n",
    "\n",
    "# Create a list of words from my string with stopwords removed and assign to variable.\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "# Join words in the list back into strings and assign to a variable.\n",
    "string_without_stopwords = ' '.join(filtered_words)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of stopwords.\n",
    "\n",
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['german',\n",
       " 'scientist',\n",
       " 'uur',\n",
       " 'ahin',\n",
       " 'the',\n",
       " 'ceo',\n",
       " 'of',\n",
       " 'biontech',\n",
       " 'which',\n",
       " 'codeveloped']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split words in lemmatized column\n",
    "\n",
    "words = article.split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['german',\n",
       " 'scientist',\n",
       " 'uur',\n",
       " 'ahin',\n",
       " 'ceo',\n",
       " 'biontech',\n",
       " 'codeveloped',\n",
       " 'coronavirus',\n",
       " 'vaccine',\n",
       " 'pfizer']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of words from my string with stopwords removed and assign to variable.\n",
    "\n",
    "filtered_words = [word for word in words if word not in stopword_list]\n",
    "filtered_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin ceo biontech codeveloped coronavirus vaccine pfizer said hes confident product end pandemic bash virus head vaccine 90 effective based initial data latestage trial believe even protection symptomatic infections dramatic effect ahin said'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join words in the list back into strings and assign to a variable.\n",
    "\n",
    "string_without_stopwords = ' '.join(filtered_words)\n",
    "string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopwords Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove additional exclude_words.\n",
    "    stopword_list = stopword_list.extend(exclude_words)\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Add additional extra_words.\n",
    "    filtered_words.extend(extra_words)\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Article Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vacc...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Father said 'if you want to blow money up, fin...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  Scientist behind '90% effective' COVID-19 vacc...   \n",
       "1  business  Father said 'if you want to blow money up, fin...   \n",
       "\n",
       "                   author                                            content  \n",
       "0  Krishna Veera Vanamali  German scientist Uğur Şahin, the CEO of BioNTe...  \n",
       "1          Pragya Swastik  Serum Institute of India's (SII) CEO Adar Poon...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_news_articles(cached=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article(df):\n",
    "    '''\n",
    "    This function\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string with original columns plus cleaned\n",
    "    and lemmatized content without stopwords.\n",
    "    '''\n",
    "    # Do basic clean on article content.\n",
    "    df = basic_clean(df, 'content')\n",
    "    \n",
    "    # Tokenize clean article content.\n",
    "    df = tokenize(df, 'basic_clean')\n",
    "    \n",
    "    # Stem cleaned and tokenized article content.\n",
    "    df = stem(df, 'clean_tokens')\n",
    "    \n",
    "    # Remove stopwords from Lemmatized article content.\n",
    "    df = remove_stopwords(df, 'stemmed')\n",
    "    \n",
    "    # Lemmatize cleaned and tokenized article content.\n",
    "    df = lemmatize(df, 'clean_tokens')\n",
    "    \n",
    "    # Remove stopwords from Lemmatized article content.\n",
    "    df = remove_stopwords(df, 'lemmatized')\n",
    "    \n",
    "    return df[['topic', 'title', 'author', 'content', 'clean_stemmed', 'clean_lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_stemmed</th>\n",
       "      <th>clean_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vaccine says it can end the pandemic</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he's confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protect...</td>\n",
       "      <td>german scientist uur ahin ceo biontech codevelop coronaviru vaccin pfizer said confid hi product end pandem bash viru head vaccin 90 effect base initi data latestag trial believ even protect onli symptomat infect dramat effect ahin said</td>\n",
       "      <td>german scientist uur ahin ceo biontech codeveloped coronavirus vaccine pfizer said confident product end pandemic bash virus head vaccine 90 effective based initial data latestage trial believe even protection symptomatic infection dramatic effect ahin said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Father said 'if you want to blow money up, fine' as I put $250M on vaccine: Adar</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poonawalla revealed that his father Cyrus S Poonawalla told him, \"Look, it's your money. If you want to blow it up, fine,\" as he put $250 million in ramping up COVID-19 vaccine manufacturing capacity. Adar told The Washington Post, \"I decided to go all o...</td>\n",
       "      <td>serum institut india sii ceo adar poonawalla reveal hi father cyru poonawalla told look money want blow fine put 250 million ramp covid19 vaccin manufactur capac adar told washington post decid go hi father found sii 1966</td>\n",
       "      <td>serum institute india sii ceo adar poonawalla revealed father cyrus poonawalla told look money want blow fine put 250 million ramping covid19 vaccine manufacturing capacity adar told washington post decided go father founded sii 1966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic  \\\n",
       "0  business   \n",
       "1  business   \n",
       "\n",
       "                                                                              title  \\\n",
       "0    Scientist behind '90% effective' COVID-19 vaccine says it can end the pandemic   \n",
       "1  Father said 'if you want to blow money up, fine' as I put $250M on vaccine: Adar   \n",
       "\n",
       "                   author  \\\n",
       "0  Krishna Veera Vanamali   \n",
       "1          Pragya Swastik   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                       content  \\\n",
       "0  German scientist Uğur Şahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he's confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protect...   \n",
       "1  Serum Institute of India's (SII) CEO Adar Poonawalla revealed that his father Cyrus S Poonawalla told him, \"Look, it's your money. If you want to blow it up, fine,\" as he put $250 million in ramping up COVID-19 vaccine manufacturing capacity. Adar told The Washington Post, \"I decided to go all o...   \n",
       "\n",
       "                                                                                                                                                                                                                                  clean_stemmed  \\\n",
       "0  german scientist uur ahin ceo biontech codevelop coronaviru vaccin pfizer said confid hi product end pandem bash viru head vaccin 90 effect base initi data latestag trial believ even protect onli symptomat infect dramat effect ahin said   \n",
       "1                 serum institut india sii ceo adar poonawalla reveal hi father cyru poonawalla told look money want blow fine put 250 million ramp covid19 vaccin manufactur capac adar told washington post decid go hi father found sii 1966   \n",
       "\n",
       "                                                                                                                                                                                                                                                    clean_lemmatized  \n",
       "0  german scientist uur ahin ceo biontech codeveloped coronavirus vaccine pfizer said confident product end pandemic bash virus head vaccine 90 effective based initial data latestage trial believe even protection symptomatic infection dramatic effect ahin said  \n",
       "1                          serum institute india sii ceo adar poonawalla revealed father cyrus poonawalla told look money want blow fine put 250 million ramping covid19 vaccine manufacturing capacity adar told washington post decided go father founded sii 1966  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_article_data(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
