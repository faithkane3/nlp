{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nlp_acquire import get_news_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>What is Natural Language Processing?</font>\n",
    "\n",
    "Natural Language Processing allows you to use techniques in Python libraries like NLTK (Natural Language Tool Kit) and Spacy to create a machine-useable structure out of natural language text. In other words, you can manipulate natural language in such a way that renders it useful in machine learning. Machines can't read words, but they can recognize numbers, so we have to process the text we want to use in a way that retains the original meaning while representing the text with numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>So What?</font>\n",
    "\n",
    "We will establish a workflow to preprocess our text data and prepare it for further use in exploration and modeling. This preprocessing is know as text normalization. **Normalization** is when you perform a series of tasks like making all text lowercase, removing punctuation, expanding contractions, removing anything that's not an ASCII character, etc.\n",
    "\n",
    "1. Lowercase all characters in our string.\n",
    "2. Remove accented & non-ASCII characters from our string.\n",
    "3. Remove special characters from our string.\n",
    "4. Tokenize our string into discrete units. (words, punctuation)\n",
    "5. Stem and Lemmatize the words in our string. (group by base word)\n",
    "6. Remove stopwords from our string. (remove noise)\n",
    "7. Store original and cleaned text for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=green>Now What?</font>\n",
    "\n",
    "Let's create functions to help us preprocess our text data. According to the curriculum, we should build our functions to take in a string. We can use the `.apply()` method when it's time to use our functions on a Series in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vacc...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Father said 'if you want to blow money up, fin...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>China suspends fish imports from Indian firm a...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>China has suspended imports from India's Basu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Russian vaccine arrives in India, video of it ...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>Russia's coronavirus vaccine, Sputnik V, has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Special Indian version of PUBG Mobile to be la...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>South Korea's PUBG Corporation on Thursday ann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  Scientist behind '90% effective' COVID-19 vacc...   \n",
       "1  business  Father said 'if you want to blow money up, fin...   \n",
       "2  business  China suspends fish imports from Indian firm a...   \n",
       "3  business  Russian vaccine arrives in India, video of it ...   \n",
       "4  business  Special Indian version of PUBG Mobile to be la...   \n",
       "\n",
       "                   author                                            content  \n",
       "0  Krishna Veera Vanamali  German scientist Uğur Şahin, the CEO of BioNTe...  \n",
       "1          Pragya Swastik  Serum Institute of India's (SII) CEO Adar Poon...  \n",
       "2  Krishna Veera Vanamali  China has suspended imports from India's Basu ...  \n",
       "3  Krishna Veera Vanamali  Russia's coronavirus vaccine, Sputnik V, has a...  \n",
       "4  Krishna Veera Vanamali  South Korea's PUBG Corporation on Thursday ann...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read our text data into a pandas DataFrame from our saved json file.\n",
    "\n",
    "df = get_news_articles(cached=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    German scientist Uğur Şahin, the CEO of BioNTe...\n",
       "1    Serum Institute of India's (SII) CEO Adar Poon...\n",
       "2    China has suspended imports from India's Basu ...\n",
       "3    Russia's coronavirus vaccine, Sputnik V, has a...\n",
       "4    South Korea's PUBG Corporation on Thursday ann...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = df.content\n",
    "print(type(articles))\n",
    "articles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protection only from symptomatic infections will have a dramatic effect,\" Şahin said.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a string that I will use to test my funtions; this is just the first row in my Series.\n",
    "\n",
    "article = articles[0]\n",
    "print(type(article))\n",
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lowercase Text\n",
    "```python\n",
    "# Make all characters in string lowercase.\n",
    "string = string.lower()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uğur şahin, the ceo of biontech which co-developed a coronavirus vaccine with pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" the vaccine is 90% effective based on initial data from a late-stage trial. \"i believe that even protection only from symptomatic infections will have a dramatic effect,\" şahin said.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note I have to reassign this to save the changes.\n",
    "\n",
    "article.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Accented Characters\n",
    "\n",
    "We will remove accented characters by chaining together the following methods:\n",
    "\n",
    "```python\n",
    "# Remove inconsistencies in unicode character encoding.\n",
    "string = unicodedata.normalize(form, unistr)\n",
    "```\n",
    "\n",
    "```python\n",
    "# Convert string to ASCII character set and drop non-ASCII characters.\n",
    "string = string.encode('ascii', 'ignore')\n",
    "```\n",
    "\n",
    "```python\n",
    "# Convert the bytes back into a string object.\n",
    "string = string.decode('utf-8', 'ignore')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uur ahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protection only from symptomatic infections will have a dramatic effect,\" ahin said.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to reassign to my variable if I want to save the changes.\n",
    "\n",
    "unicodedata.normalize('NFKC', article).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove Special Characters\n",
    "\n",
    "Here are two common patterns I might want to use to remove special characters; it just depends on what you want to remain in your string.\n",
    "\n",
    "```python\n",
    "# Remove characters that are not letters, underscores, or spaces.\n",
    "string = re.sub(r'[^\\w\\s]', '', string)\n",
    "\n",
    "# Remove characters that are not letters, numbers, single quotes, or spaces.\n",
    "string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin the CEO of BioNTech which codeveloped a coronavirus vaccine with Pfizer said hes confident his product can end the pandemic and bash the virus over the head The vaccine is 90 effective based on initial data from a latestage trial I believe that even protection only from symptomatic infections will have a dramatic effect Şahin said'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test our regex on our string first; we have to reassign if we want to save the changes.\n",
    "\n",
    "re.sub(r'[^\\w\\s]', '', article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Clean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns the string normalized.\n",
    "    '''\n",
    "    string = unicodedata.normalize('NFKC', string)\\\n",
    "             .encode('ascii', 'ignore')\\\n",
    "             .decode('utf-8', 'ignore')\n",
    "    string = re.sub(r'[^\\w\\s]', '', string).lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uur ahin the ceo of biontech which codeveloped a coronavirus vaccine with pfizer said hes confident his product can end the pandemic and bash the virus over the head the vaccine is 90 effective based on initial data from a latestage trial i believe that even protection only from symptomatic infections will have a dramatic effect ahin said'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Text\n",
    "\n",
    "**Tokenization** - is when you split larger strings of text into smaller pieces or tokens by setting a boundary. You might chunk a sentence into words using a space as a boundary or a paragraph into sentences using punctuation as a boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK Tokenization\n",
    "\n",
    "```python\n",
    "# Create the tokenizer\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "# Use the tokenizer on my string and assign to a variable. \n",
    "tokenized_string = tokenizer.tokenize(string, return_str=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenizer\n",
    "\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin , the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer , said he \\' s confident his product can end the pandemic and \" bash the virus over the head. \" The vaccine is 90 % effective based on initial data from a late-stage trial. \" I believe that even protection only from symptomatic infections will have a dramatic effect , \" Şahin said .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the tokenizer on my string; assign to variable to save changes\n",
    "\n",
    "tokenizer.tokenize(article, return_str=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin , the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer , said he \\' s confident his product can end the pandemic and \" bash the virus over the head. \" The vaccine is 90 % effective based on initial data from a late-stage trial. \" I believe that even protection only from symptomatic infections will have a dramatic effect , \" Şahin said .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stem Words\n",
    "\n",
    "**Stemming** is when you reduce related words in your text to their common stem. It can make it easier when you are searching for a particular word in your text to search for their common stem rather than every form of the word. Stemmers aren't that sophisticated in the way they chop off word endings at their common stems; Spacy, another python NLP library, doesn't even include a stemmer in their library. Spacy only offers the more sophisticated lemmatizer, which we will look at in NLTK next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK PorterStemmer\n",
    "\n",
    "```python\n",
    "# Create the Stemmer.\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Apply the stemmer to each word in our string.\n",
    "stems = [ps.stem(word) for word in string.split()]\n",
    "```\n",
    "\n",
    "```python\n",
    "# Join our lists of words into strings again and assign to a variable.\n",
    "stemmed_string = ' '.join('stems')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create porter stemmer.\n",
    "\n",
    "ps = nltk.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check stemmer. It works.\n",
    "\n",
    "ps.stem('Called')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['german',\n",
       " 'scientist',\n",
       " 'uğur',\n",
       " 'şahin,',\n",
       " 'the',\n",
       " 'ceo',\n",
       " 'of',\n",
       " 'biontech',\n",
       " 'which',\n",
       " 'co-develop']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the stemmer to each word in our string.\n",
    "\n",
    "stems = [ps.stem(word) for word in article.split()]\n",
    "stems[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uğur şahin, the ceo of biontech which co-develop a coronaviru vaccin with pfizer, said he\\' confid hi product can end the pandem and \"bash the viru over the head.\" the vaccin is 90% effect base on initi data from a late-stag trial. \"I believ that even protect onli from symptomat infect will have a dramat effect,\" şahin said.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join our lists of words into a string again; assign to a variable to save changes\n",
    "\n",
    "' '.join(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stem Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german scientist uğur şahin, the ceo of biontech which co-develop a coronaviru vaccin with pfizer, said he\\' confid hi product can end the pandem and \"bash the viru over the head.\" the vaccin is 90% effect base on initi data from a late-stag trial. \"I believ that even protect onli from symptomat infect will have a dramat effect,\" şahin said.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize Words\n",
    "\n",
    "**Lemmatization** - is when you reduce related words in your text to their lemma or word base by applying a morphological analysis to your text. Like stemming, this is done to reduce the number of forms you have of the same word, so they can be analyzed as a single item. While stemming might create tokens that are not actually words anymore after they have been chopped off at their base, lemmatization will leave you with real words. A drawback to lemmatization is that it takes longer than stemming; you can try both to see which gives you better results as you analyze a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK WordNetLemmatizer\n",
    "\n",
    "```python\n",
    "# Download the first time.\n",
    "nltk.download('wordnet')\n",
    "```\n",
    "\n",
    "```python\n",
    "# Create the Lemmatizer.\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Use the lemmatizer on each word in the list of words we created by using split.\n",
    "lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "```\n",
    "\n",
    "```python\n",
    "# Join our list of words into a string again and assign to a variable.\n",
    "lemmatized_string = ' '.join(lemmas)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Lemmatizer.\n",
    "\n",
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calls'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check lemmatizer. It works.\n",
    "\n",
    "wnl.lemmatize('Calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['German',\n",
       " 'scientist',\n",
       " 'Uğur',\n",
       " 'Şahin,',\n",
       " 'the',\n",
       " 'CEO',\n",
       " 'of',\n",
       " 'BioNTech',\n",
       " 'which',\n",
       " 'co-developed']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the lemmatizer on each word in the list of words we created by using split.\n",
    "\n",
    "lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protection only from symptomatic infection will have a dramatic effect,\" Şahin said.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join our list of words into a string again; assign to a variable to save changes.\n",
    "\n",
    "' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there differences between the stemmed and lemmatized strings? Yes.\n",
    "\n",
    "stems == lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin, the CEO of BioNTech which co-developed a coronavirus vaccine with Pfizer, said he\\'s confident his product can end the pandemic and \"bash the virus over the head.\" The vaccine is 90% effective based on initial data from a late-stage trial. \"I believe that even protection only from symptomatic infection will have a dramatic effect,\" Şahin said.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The functions are indeed doing different things here. Just checking...\n",
    "\n",
    "lemmatize(article) == stem(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords\n",
    "\n",
    "**Stopwords** - are words which are filtered out during the preparation of your text for analyzation and modeling. Stopwords are those that offer little to the meaning of your text and are basically just adding noise to your analysis. Or, as Ryan Orsinger would say, \"Stopwords aren't the real story of the document.\" Words such as 'the', 'and', 'a', and the like can be removed, so you can better focus on the good stuff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using NLTK Stopwords\n",
    "\n",
    "```python\n",
    "# Download the first time.\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Create list of stopwords and assign to variable.\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "# Create list of words and assign to variable.\n",
    "words = string.split()\n",
    "\n",
    "# Create a list of words from my string with stopwords removed and assign to variable.\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "# Join words in the list back into strings and assign to a variable.\n",
    "string_without_stopwords = ' '.join(filtered_words)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list of stopwords.\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['German',\n",
       " 'scientist',\n",
       " 'Uğur',\n",
       " 'Şahin,',\n",
       " 'the',\n",
       " 'CEO',\n",
       " 'of',\n",
       " 'BioNTech',\n",
       " 'which',\n",
       " 'co-developed']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split words in lemmatized column.\n",
    "\n",
    "words = article.split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['German',\n",
       " 'scientist',\n",
       " 'Uğur',\n",
       " 'Şahin,',\n",
       " 'CEO',\n",
       " 'BioNTech',\n",
       " 'co-developed',\n",
       " 'coronavirus',\n",
       " 'vaccine',\n",
       " 'Pfizer,']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of words from my string with stopwords removed and assign to variable.\n",
    "\n",
    "filtered_words = [word for word in words if word not in stopword_list]\n",
    "filtered_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin, CEO BioNTech co-developed coronavirus vaccine Pfizer, said he\\'s confident product end pandemic \"bash virus head.\" The vaccine 90% effective based initial data late-stage trial. \"I believe even protection symptomatic infections dramatic effect,\" Şahin said.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join words in the list back into strings; assign to a variable to keep changes.\n",
    "\n",
    "' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopwords Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove additional exclude_words.\n",
    "    stopword_list.extend(exclude_words)\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Add additional extra_words.\n",
    "    filtered_words.extend(extra_words)\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'German scientist Uğur Şahin, CEO BioNTech co-developed coronavirus vaccine Pfizer, said he\\'s confident product end pandemic \"bash virus head.\" The vaccine 90% effective based initial data late-stage trial. \"I believe even protection symptomatic infections dramatic effect,\" Şahin said.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scientist Uğur Şahin, CEO BioNTech co-developed coronavirus vaccine Pfizer, said he\\'s confident product end pandemic \"bash virus head.\" The vaccine 90% effective based initial data late-stage trial. \"I believe even protection symptomatic infections dramatic effect,\" Şahin said. USAA Codeup'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test my function for adding extra_words and removing exclude_words passed as arguments. \n",
    "\n",
    "remove_stopwords(article, extra_words=['USAA', 'Codeup'], exclude_words=['German'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Article Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     german scientist uur ahin ceo biontech codevel...\n",
       "1     serum institute india sii ceo adar poonawalla ...\n",
       "2     china suspended import india basu internationa...\n",
       "3     russia coronavirus vaccine sputnik v arrived i...\n",
       "4     south korea pubg corporation thursday announce...\n",
       "                            ...                        \n",
       "93    actor tiger shroffs sister krishna shroff brok...\n",
       "94    nikhil dwivedi recently opened tweet wherein t...\n",
       "95    singer selena gomez play peruvian mountaineer ...\n",
       "96    actress sayani gupta said year diwali people l...\n",
       "97    talking late actor asif basra found hanging pr...\n",
       "Name: content, Length: 98, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm checking my code before I throw it in my function; always check it first!\n",
    "\n",
    "df['content'].apply(basic_clean)\\\n",
    "             .apply(tokenize)\\\n",
    "             .apply(remove_stopwords)\\\n",
    "             .apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vacc...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Father said 'if you want to blow money up, fin...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  Scientist behind '90% effective' COVID-19 vacc...   \n",
       "1  business  Father said 'if you want to blow money up, fin...   \n",
       "\n",
       "                   author                                            content  \n",
       "0  Krishna Veera Vanamali  German scientist Uğur Şahin, the CEO of BioNTe...  \n",
       "1          Pragya Swastik  Serum Institute of India's (SII) CEO Adar Poon...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_news_articles(cached=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article_data(df, column, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function take in a df and the string name for a text column with \n",
    "    option to pass lists for extra_words and exclude_words and\n",
    "    returns a df with the text article title, original text, stemmed text,\n",
    "    lemmatized text, cleaned, tokenized, & lemmatized text with stopwords removed.\n",
    "    '''\n",
    "    df['clean'] = df[column].apply(basic_clean)\\\n",
    "                            .apply(tokenize)\\\n",
    "                            .apply(remove_stopwords, \n",
    "                                   extra_words=extra_words, \n",
    "                                   exclude_words=exclude_words)\\\n",
    "                            .apply(lemmatize)\n",
    "    \n",
    "    df['stemmed'] = df[column].apply(basic_clean).apply(stem)\n",
    "    \n",
    "    df['lemmatized'] = df[column].apply(basic_clean).apply(lemmatize)\n",
    "    \n",
    "    return df[['title', column, 'stemmed', 'lemmatized', 'clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vacc...</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTe...</td>\n",
       "      <td>german scientist uur ahin the ceo of biontech ...</td>\n",
       "      <td>german scientist uur ahin the ceo of biontech ...</td>\n",
       "      <td>german scientist uur ahin ceo biontech codevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Father said 'if you want to blow money up, fin...</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poon...</td>\n",
       "      <td>serum institut of india sii ceo adar poonawall...</td>\n",
       "      <td>serum institute of india sii ceo adar poonawal...</td>\n",
       "      <td>serum institute india sii ceo adar poonawalla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China suspends fish imports from Indian firm a...</td>\n",
       "      <td>China has suspended imports from India's Basu ...</td>\n",
       "      <td>china ha suspend import from india basu intern...</td>\n",
       "      <td>china ha suspended import from india basu inte...</td>\n",
       "      <td>china suspended import india basu internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russian vaccine arrives in India, video of it ...</td>\n",
       "      <td>Russia's coronavirus vaccine, Sputnik V, has a...</td>\n",
       "      <td>russia coronaviru vaccin sputnik v ha arriv in...</td>\n",
       "      <td>russia coronavirus vaccine sputnik v ha arrive...</td>\n",
       "      <td>russia coronavirus vaccine sputnik v arrived i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Special Indian version of PUBG Mobile to be la...</td>\n",
       "      <td>South Korea's PUBG Corporation on Thursday ann...</td>\n",
       "      <td>south korea pubg corpor on thursday announc th...</td>\n",
       "      <td>south korea pubg corporation on thursday annou...</td>\n",
       "      <td>south korea pubg corporation thursday announce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Scientist behind '90% effective' COVID-19 vacc...   \n",
       "1  Father said 'if you want to blow money up, fin...   \n",
       "2  China suspends fish imports from Indian firm a...   \n",
       "3  Russian vaccine arrives in India, video of it ...   \n",
       "4  Special Indian version of PUBG Mobile to be la...   \n",
       "\n",
       "                                             content  \\\n",
       "0  German scientist Uğur Şahin, the CEO of BioNTe...   \n",
       "1  Serum Institute of India's (SII) CEO Adar Poon...   \n",
       "2  China has suspended imports from India's Basu ...   \n",
       "3  Russia's coronavirus vaccine, Sputnik V, has a...   \n",
       "4  South Korea's PUBG Corporation on Thursday ann...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  german scientist uur ahin the ceo of biontech ...   \n",
       "1  serum institut of india sii ceo adar poonawall...   \n",
       "2  china ha suspend import from india basu intern...   \n",
       "3  russia coronaviru vaccin sputnik v ha arriv in...   \n",
       "4  south korea pubg corpor on thursday announc th...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  german scientist uur ahin the ceo of biontech ...   \n",
       "1  serum institute of india sii ceo adar poonawal...   \n",
       "2  china ha suspended import from india basu inte...   \n",
       "3  russia coronavirus vaccine sputnik v ha arrive...   \n",
       "4  south korea pubg corporation on thursday annou...   \n",
       "\n",
       "                                               clean  \n",
       "0  german scientist uur ahin ceo biontech codevel...  \n",
       "1  serum institute india sii ceo adar poonawalla ...  \n",
       "2  china suspended import india basu internationa...  \n",
       "3  russia coronavirus vaccine sputnik v arrived i...  \n",
       "4  south korea pubg corporation thursday announce...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prep_article_data(df, 'content')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientist behind '90% effective' COVID-19 vacc...</td>\n",
       "      <td>German scientist Uğur Şahin, the CEO of BioNTe...</td>\n",
       "      <td>german scientist uur ahin the ceo of biontech ...</td>\n",
       "      <td>german scientist uur ahin the ceo of biontech ...</td>\n",
       "      <td>scientist uur ahin ceo biontech codeveloped co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Father said 'if you want to blow money up, fin...</td>\n",
       "      <td>Serum Institute of India's (SII) CEO Adar Poon...</td>\n",
       "      <td>serum institut of india sii ceo adar poonawall...</td>\n",
       "      <td>serum institute of india sii ceo adar poonawal...</td>\n",
       "      <td>serum institute india sii ceo adar poonawalla ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China suspends fish imports from Indian firm a...</td>\n",
       "      <td>China has suspended imports from India's Basu ...</td>\n",
       "      <td>china ha suspend import from india basu intern...</td>\n",
       "      <td>china ha suspended import from india basu inte...</td>\n",
       "      <td>suspended import india basu international one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russian vaccine arrives in India, video of it ...</td>\n",
       "      <td>Russia's coronavirus vaccine, Sputnik V, has a...</td>\n",
       "      <td>russia coronaviru vaccin sputnik v ha arriv in...</td>\n",
       "      <td>russia coronavirus vaccine sputnik v ha arrive...</td>\n",
       "      <td>russia coronavirus vaccine sputnik v arrived i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Special Indian version of PUBG Mobile to be la...</td>\n",
       "      <td>South Korea's PUBG Corporation on Thursday ann...</td>\n",
       "      <td>south korea pubg corpor on thursday announc th...</td>\n",
       "      <td>south korea pubg corporation on thursday annou...</td>\n",
       "      <td>south korea pubg corporation thursday announce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Tiger's sister Krishna announces split from Eb...</td>\n",
       "      <td>Actor Tiger Shroff's sister, Krishna Shroff, h...</td>\n",
       "      <td>actor tiger shroff sister krishna shroff ha br...</td>\n",
       "      <td>actor tiger shroffs sister krishna shroff ha b...</td>\n",
       "      <td>actor tiger shroffs sister krishna shroff brok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>It was a mark of protest: Nikhil on tweet sayi...</td>\n",
       "      <td>Nikhil Dwivedi recently opened up about his tw...</td>\n",
       "      <td>nikhil dwivedi recent open up about hi tweet w...</td>\n",
       "      <td>nikhil dwivedi recently opened up about his tw...</td>\n",
       "      <td>nikhil dwivedi recently opened tweet wherein t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Selena to play mountaineer Silvia Vasquez-Lava...</td>\n",
       "      <td>Singer Selena Gomez will play Peruvian mountai...</td>\n",
       "      <td>singer selena gomez will play peruvian mountai...</td>\n",
       "      <td>singer selena gomez will play peruvian mountai...</td>\n",
       "      <td>singer selena gomez play peruvian mountaineer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hope old demons are left behind and we adopt p...</td>\n",
       "      <td>Actress Sayani Gupta said that this year on Di...</td>\n",
       "      <td>actress sayani gupta said that thi year on diw...</td>\n",
       "      <td>actress sayani gupta said that this year on di...</td>\n",
       "      <td>actress sayani gupta said year diwali people l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Asif told me Dharamshala was his go-to place f...</td>\n",
       "      <td>Talking about late actor Asif Basra who was fo...</td>\n",
       "      <td>talk about late actor asif basra who wa found ...</td>\n",
       "      <td>talking about late actor asif basra who wa fou...</td>\n",
       "      <td>talking late actor asif basra found hanging pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Scientist behind '90% effective' COVID-19 vacc...   \n",
       "1   Father said 'if you want to blow money up, fin...   \n",
       "2   China suspends fish imports from Indian firm a...   \n",
       "3   Russian vaccine arrives in India, video of it ...   \n",
       "4   Special Indian version of PUBG Mobile to be la...   \n",
       "..                                                ...   \n",
       "93  Tiger's sister Krishna announces split from Eb...   \n",
       "94  It was a mark of protest: Nikhil on tweet sayi...   \n",
       "95  Selena to play mountaineer Silvia Vasquez-Lava...   \n",
       "96  Hope old demons are left behind and we adopt p...   \n",
       "97  Asif told me Dharamshala was his go-to place f...   \n",
       "\n",
       "                                              content  \\\n",
       "0   German scientist Uğur Şahin, the CEO of BioNTe...   \n",
       "1   Serum Institute of India's (SII) CEO Adar Poon...   \n",
       "2   China has suspended imports from India's Basu ...   \n",
       "3   Russia's coronavirus vaccine, Sputnik V, has a...   \n",
       "4   South Korea's PUBG Corporation on Thursday ann...   \n",
       "..                                                ...   \n",
       "93  Actor Tiger Shroff's sister, Krishna Shroff, h...   \n",
       "94  Nikhil Dwivedi recently opened up about his tw...   \n",
       "95  Singer Selena Gomez will play Peruvian mountai...   \n",
       "96  Actress Sayani Gupta said that this year on Di...   \n",
       "97  Talking about late actor Asif Basra who was fo...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   german scientist uur ahin the ceo of biontech ...   \n",
       "1   serum institut of india sii ceo adar poonawall...   \n",
       "2   china ha suspend import from india basu intern...   \n",
       "3   russia coronaviru vaccin sputnik v ha arriv in...   \n",
       "4   south korea pubg corpor on thursday announc th...   \n",
       "..                                                ...   \n",
       "93  actor tiger shroff sister krishna shroff ha br...   \n",
       "94  nikhil dwivedi recent open up about hi tweet w...   \n",
       "95  singer selena gomez will play peruvian mountai...   \n",
       "96  actress sayani gupta said that thi year on diw...   \n",
       "97  talk about late actor asif basra who wa found ...   \n",
       "\n",
       "                                           lemmatized  \\\n",
       "0   german scientist uur ahin the ceo of biontech ...   \n",
       "1   serum institute of india sii ceo adar poonawal...   \n",
       "2   china ha suspended import from india basu inte...   \n",
       "3   russia coronavirus vaccine sputnik v ha arrive...   \n",
       "4   south korea pubg corporation on thursday annou...   \n",
       "..                                                ...   \n",
       "93  actor tiger shroffs sister krishna shroff ha b...   \n",
       "94  nikhil dwivedi recently opened up about his tw...   \n",
       "95  singer selena gomez will play peruvian mountai...   \n",
       "96  actress sayani gupta said that this year on di...   \n",
       "97  talking about late actor asif basra who wa fou...   \n",
       "\n",
       "                                                clean  \n",
       "0   scientist uur ahin ceo biontech codeveloped co...  \n",
       "1   serum institute india sii ceo adar poonawalla ...  \n",
       "2   suspended import india basu international one ...  \n",
       "3   russia coronavirus vaccine sputnik v arrived i...  \n",
       "4   south korea pubg corporation thursday announce...  \n",
       "..                                                ...  \n",
       "93  actor tiger shroffs sister krishna shroff brok...  \n",
       "94  nikhil dwivedi recently opened tweet wherein t...  \n",
       "95  singer selena gomez play peruvian mountaineer ...  \n",
       "96  actress sayani gupta said year diwali people l...  \n",
       "97  talking late actor asif basra found hanging pr...  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_article_data(df, 'content', extra_words=['Codeup'], exclude_words=['german', 'china'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
