{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from requests import get\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>What is Beautiful Soup?</font>\n",
    "\n",
    "Beautiful Soup is a Python library for scraping dta from an HTML document. You have to be careful when scraping data from sites that the site allows the practice. You can check by typing `/robots.txt` after the base url of a site. Using the `headers` parameter in your request is also a part of web scraping best practices.\n",
    "\n",
    "Check out the docs for BeautifulSoup [here](https://beautiful-soup-4.readthedocs.io/en/latest/). I also found it very useful to code along with some articles and tutorials I found online to get a feel for scraping.\n",
    "\n",
    "- Simple but useful web scraping with Beautiful Soup [article](https://www.pluralsight.com/guides/web-scraping-with-beautiful-soup).\n",
    "\n",
    "- Dataquest [tutorial](https://www.dataquest.io/blog/web-scraping-beautifulsoup/) from the curriculum and intro Dataquest [tutorial](https://www.dataquest.io/blog/web-scraping-tutorial-python/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=orange>So How Do We Use Beautiful Soup?</font>\n",
    "\n",
    "Here, we are looking to retrieve content from a web page, but the web page is written in HTML (HyperText Markup Language), so we will use the `requests` library to get a response with the HTML from our desired page and `BeautifulSoup` to parse the HTML response. As you begin scraping, it would be helpful to have a basic understanding of the different HTML elements and attributes used to create web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HTML Tree Diagram\n",
    "\n",
    "![HTML Tree Diagram Image](https://drek4537l1klr.cloudfront.net/mcfedries/Figures/19_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HTML Elements\n",
    "\n",
    "An HTML element consists of a start tag and an end tag along with the content between the tags. For example:\n",
    "\n",
    "```html\n",
    "<div>content...content</div>\n",
    "```\n",
    "\n",
    "HTML elements can be nested or contain other elements. For example:\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "\n",
    "<h1>My First Heading</h1>\n",
    "<p>My first paragraph.</p>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "___\n",
    "\n",
    "`<html>` tags define the html element --- the whole document.\n",
    "\n",
    "`<body>` tags define the body element --- the document body.\n",
    "\n",
    "`<h1>` to `<h6>` tags define a heading element --- a heading. \n",
    "- (`<h1>` - `<h6>`, largest to smallest heading size)\n",
    "\n",
    "`<p>` tags define a paragraph element --- a new pargraph of text.\n",
    "\n",
    "`<a>` tags define an anchor element, which tells the browser to render a hyperlink to a web page, file, email address, etc. Anchor elements use the `href` attribute to tell the link where to go.\n",
    "\n",
    "```html\n",
    "<a href='url_of_link'>Text of the link</a>\n",
    "```\n",
    "\n",
    "`<div>` tags define a division element, like a container; it is used to group and style block-level content using the `class` or `id` attributes (defined below).\n",
    "\n",
    "`<span>` element is also like a container, like the `<div>` element above, but for styling inline elements instead of block-level.\n",
    "\n",
    "`<img>` element defines an image and uses the `src` attribute to hold the image address. The `<img>` tag is self-closing, which mean it doesn't need a closing tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HTML or Tag Attributes\n",
    "\n",
    "These are optional and appear inside of the opening tag, usually as name/value pairs `name='value'`. They make the HTML elements easier to work with because they give the elements names. For example, let's add a class attribute to our `<div>` element from above.\n",
    "\n",
    "```html\n",
    "<div class='descriptive_class_name'>content...content</div>\n",
    "```\n",
    "\n",
    "`class` is an attribute of an HTML element that defines equal styles for tags with the same class. One element can have multiple classes and different elements can share the same classes, so classes cannot be used as unique identifiers.\n",
    "\n",
    "`id` is an attribute of an HTML element. Each element can only have one id, so they can be used as unique identifiers.\n",
    "\n",
    "`itemprop` is an attribute that consists of a name-value pair and is used to add properties to an element.\n",
    "\n",
    "`href` is an attribute of an `<a>` element that contains the link address.\n",
    "\n",
    "```html\n",
    "<a href=“destination.com”></a>\n",
    "\n",
    "```\n",
    "\n",
    "`src` is an attribute of an `<img>` element that contains the address for an image. I can size my image using the `width=` and `height=` attributes, as well, if I like.\n",
    "```html\n",
    "<img src=\"img_name.jpg\" width=\"500\" height=\"600\">\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=green>Now What?</font>\n",
    "\n",
    "![Web Scraping Workflow Image](https://i.pinimg.com/564x/13/ff/c9/13ffc9bddace4005d58222755647879c.jpg)\n",
    "\n",
    "**Inspect** the structure of the web page by right-clicking on the part or parts of the page we want to scrape and clicking `inspect`. We can also inspect the source code of a web page by prefixing the url in the address bar of our browser with 'view-source:' like in the example below. This method returns the HTML as it is returned in your request, without any extra information.\n",
    "```python\n",
    "view-source:https://ryanorsinger.com/\n",
    "```\n",
    "\n",
    "**Obtain** the HTML from our target web page using the `requests` library . You can review how to use the `requests` library in my notebook [here](https://darden_reviews.github.io/api_review).\n",
    "```python\n",
    "url = 'https://ryanorsinger.com/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'} \n",
    "    \n",
    "response = get(url, headers=headers)\n",
    "```\n",
    "\n",
    "**Parse** the HTML we receive from our request using Python's Beautiful Soup library. We do this by passing our string of HTML or an HTML file and a parser to BeautifulSoup. This is how we **Create** the Soup object that we will work with in extracting data using element names, attributes, and selectors.\n",
    "```python\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "```\n",
    "\n",
    "**Extract** the data we want from our Soup object.\n",
    "\n",
    "**Save** our data to a file for future use or prepare it for further use in the next step of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BeautifulSoup Methods\n",
    "\n",
    "We can use HTML tags, CSS class (`class_=''`), Regex patterns, CSS selectors, and more with `BeautifulSoup` search methods to retrieve the information we want. For example:\n",
    "```python\n",
    "\n",
    "# Create our soup object using BeautifulSoup and our response string using get() method from requests library.\n",
    "\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Extract the first instance of the specific tag_name.\n",
    "# param name -> A filter on tag name. Default: name=None\n",
    "# param attrs -> A dictionary of filters on attribute values. Default: attrs={}\n",
    "\n",
    "soup.find(name, attrs)\n",
    "\n",
    "# Extract all of the instances of the specific tag_name.\n",
    "\n",
    "soup.find_all(name, attrs)\n",
    "\n",
    "# Return a dictionary of all attributes of this tag.\n",
    "\n",
    "tag.attrs\n",
    "\n",
    "# Return all the test in this tag\n",
    "\n",
    "tag.text\n",
    "\n",
    "# Return a list of all children elements of this tag.\n",
    "\n",
    "tag.contents\n",
    "```\n",
    "\n",
    "You can find more about filtering your HTML requests with `BeautifulSoup` search methods [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'} \n",
    "    \n",
    "response = get(url, headers=headers)\n",
    "response.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Here's our long string; we'll use this to make our soup object\n",
    "\n",
    "print(type(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# Use BeautifulSoup using our response string\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Now we have our BeautifulSoup object, we can use its built-in methods and properties\n",
    "\n",
    "print(type(soup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
